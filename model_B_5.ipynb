{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.156514Z",
     "start_time": "2025-04-09T04:07:23.236807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import torch\n",
    "torch.set_printoptions(precision=6)\n"
   ],
   "id": "5982886faeeb05cc",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.171527Z",
     "start_time": "2025-04-09T04:07:27.157515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_data_A = pd.read_csv('data/data_A.csv')\n",
    "raw_data_B = pd.read_csv('data/data_B.csv')\n",
    "raw_data_C = pd.read_csv('data/data_C.csv')"
   ],
   "id": "5370605821a0497b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.186519Z",
     "start_time": "2025-04-09T04:07:27.173171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_A = raw_data_A.select_dtypes(include=[np.number])\n",
    "data_B = raw_data_B.select_dtypes(include=[np.number])\n",
    "data_C = raw_data_C.select_dtypes(include=[np.number])"
   ],
   "id": "4bb8c56c19f13e39",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.201912Z",
     "start_time": "2025-04-09T04:07:27.187520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler_1 = MinMaxScaler()\n",
    "scaler_2 = MinMaxScaler()\n",
    "scaler_3 = MinMaxScaler()"
   ],
   "id": "a5ff050c8e9ad2c4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.217586Z",
     "start_time": "2025-04-09T04:07:27.203910Z"
    }
   },
   "cell_type": "code",
   "source": "split_up_index = int(len(data_A)*0.8)",
   "id": "5887826483da2c2f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.232407Z",
     "start_time": "2025-04-09T04:07:27.218587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaled_train_data_A = scaler_1.fit_transform(data_A[:split_up_index].values)\n",
    "scaled_train_data_B = scaler_2.fit_transform(data_B[:split_up_index].values)\n",
    "scaled_train_data_C = scaler_3.fit_transform(data_C[:split_up_index].values)"
   ],
   "id": "1057157920a8406e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.247692Z",
     "start_time": "2025-04-09T04:07:27.234406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaled_test_data_A = scaler_1.transform(data_A[split_up_index:].values)\n",
    "scaled_test_data_B = scaler_2.transform(data_B[split_up_index:].values)\n",
    "scaled_test_data_C = scaler_3.transform(data_C[split_up_index:].values)"
   ],
   "id": "731022fbc1e8fbf0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.263559Z",
     "start_time": "2025-04-09T04:07:27.248695Z"
    }
   },
   "cell_type": "code",
   "source": "scaled_train_data_C[13:]",
   "id": "faa45437f4231456",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.03059766],\n",
       "       [0.04546754],\n",
       "       [0.03116957],\n",
       "       [0.04175007],\n",
       "       [0.04832714],\n",
       "       [0.0303117 ],\n",
       "       [0.02716614],\n",
       "       [0.06376894],\n",
       "       [0.25850729],\n",
       "       [0.7718044 ],\n",
       "       [0.01201029],\n",
       "       [0.01744352],\n",
       "       [0.06948813],\n",
       "       [0.05890764],\n",
       "       [0.04746926],\n",
       "       [0.05204461],\n",
       "       [0.0577638 ],\n",
       "       [0.06434086],\n",
       "       [0.06577066],\n",
       "       [0.11752931],\n",
       "       [0.31484129],\n",
       "       [0.8204175 ],\n",
       "       [0.03059766],\n",
       "       [0.02545039],\n",
       "       [0.07063197],\n",
       "       [0.08321418],\n",
       "       [0.07006005],\n",
       "       [0.08492994],\n",
       "       [0.07863883],\n",
       "       [0.07720904],\n",
       "       [0.07720904],\n",
       "       [0.11924507],\n",
       "       [0.35859308],\n",
       "       [0.86931656],\n",
       "       [0.03688876],\n",
       "       [0.04603946],\n",
       "       [0.08979125],\n",
       "       [0.08178439],\n",
       "       [0.02659422],\n",
       "       [0.07806691],\n",
       "       [0.08607378],\n",
       "       [0.0852159 ],\n",
       "       [0.08407206],\n",
       "       [0.14812697],\n",
       "       [0.4077781 ],\n",
       "       [1.        ],\n",
       "       [0.04403775],\n",
       "       [0.06148127],\n",
       "       [0.13039748],\n",
       "       [0.09150701],\n",
       "       [0.10609094],\n",
       "       [0.10408922],\n",
       "       [0.11066629],\n",
       "       [0.10923649],\n",
       "       [0.11295396],\n",
       "       [0.16156706],\n",
       "       [0.40977981],\n",
       "       [0.87703746],\n",
       "       [0.08064055],\n",
       "       [0.08778953],\n",
       "       [0.11752931],\n",
       "       [0.12753789],\n",
       "       [0.11724335],\n",
       "       [0.12582213],\n",
       "       [0.13325708],\n",
       "       [0.12839577],\n",
       "       [0.12267658],\n",
       "       [0.17758078],\n",
       "       [0.41035173],\n",
       "       [0.92221904],\n",
       "       [0.1020875 ],\n",
       "       [0.11152416],\n",
       "       [0.1598513 ],\n",
       "       [0.1429797 ],\n",
       "       [0.13869031],\n",
       "       [0.15012868],\n",
       "       [0.14498141],\n",
       "       [0.15012868],\n",
       "       [0.15298828],\n",
       "       [0.20045754],\n",
       "       [0.43465828],\n",
       "       [0.8964827 ],\n",
       "       [0.09064913],\n",
       "       [0.1218187 ],\n",
       "       [0.15155848],\n",
       "       [0.16013726],\n",
       "       [0.14183586],\n",
       "       [0.1492708 ],\n",
       "       [0.15670575],\n",
       "       [0.15899342],\n",
       "       [0.17128968],\n",
       "       [0.20274521],\n",
       "       [0.45324564],\n",
       "       [0.91135259],\n",
       "       [0.08693166],\n",
       "       [0.11295396],\n",
       "       [0.17157564],\n",
       "       [0.13926222],\n",
       "       [0.13211324],\n",
       "       [0.15184444],\n",
       "       [0.14812697],\n",
       "       [0.13983414],\n",
       "       [0.13554475],\n",
       "       [0.20789248],\n",
       "       [0.53445811],\n",
       "       [0.87274807],\n",
       "       [0.09150701],\n",
       "       [0.11152416],\n",
       "       [0.17443523],\n",
       "       [0.12525021],\n",
       "       [0.14355162],\n",
       "       [0.13983414],\n",
       "       [0.1507006 ],\n",
       "       [0.14612525],\n",
       "       [0.13497283],\n",
       "       [0.22047469],\n",
       "       [0.54103517],\n",
       "       [0.87932514],\n",
       "       [0.09551044],\n",
       "       [0.10408922],\n",
       "       [0.15298828],\n",
       "       [0.16099514],\n",
       "       [0.14641121],\n",
       "       [0.13954818],\n",
       "       [0.14812697],\n",
       "       [0.14612525],\n",
       "       [0.14841293],\n",
       "       [0.20303117],\n",
       "       [0.47097512],\n",
       "       [0.84901344],\n",
       "       [0.11038033],\n",
       "       [0.13411496],\n",
       "       [0.15699171],\n",
       "       [0.14469545],\n",
       "       [0.11381184],\n",
       "       [0.12810981],\n",
       "       [0.14583929],\n",
       "       [0.12582213],\n",
       "       [0.13583071],\n",
       "       [0.21018015],\n",
       "       [0.46068058],\n",
       "       [0.82213326],\n",
       "       [0.10694881],\n",
       "       [0.1155276 ],\n",
       "       [0.17071776],\n",
       "       [0.1492708 ],\n",
       "       [0.13869031],\n",
       "       [0.13525879],\n",
       "       [0.14326566],\n",
       "       [0.12925365],\n",
       "       [0.12668001],\n",
       "       [0.18673148],\n",
       "       [0.4415213 ],\n",
       "       [0.82785244],\n",
       "       [0.13926222],\n",
       "       [0.12753789],\n",
       "       [0.15470403],\n",
       "       [0.14812697],\n",
       "       [0.13268516],\n",
       "       [0.13497283],\n",
       "       [0.14126394],\n",
       "       [0.13354304],\n",
       "       [0.14583929],\n",
       "       [0.17986846],\n",
       "       [0.3880469 ],\n",
       "       [0.77866743],\n",
       "       [0.10637689],\n",
       "       [0.11381184],\n",
       "       [0.17500715],\n",
       "       [0.13954818],\n",
       "       [0.13554475],\n",
       "       [0.14869888],\n",
       "       [0.15041464],\n",
       "       [0.14526737],\n",
       "       [0.15041464],\n",
       "       [0.19988562],\n",
       "       [0.46668573],\n",
       "       [0.7655133 ],\n",
       "       [0.13411496],\n",
       "       [0.14355162],\n",
       "       [0.17414927],\n",
       "       [0.14469545],\n",
       "       [0.15899342],\n",
       "       [0.13411496],\n",
       "       [0.14984272],\n",
       "       [0.14040606],\n",
       "       [0.13926222],\n",
       "       [0.18444381],\n",
       "       [0.39691164],\n",
       "       [0.72891049],\n",
       "       [0.1309694 ],\n",
       "       [0.1246783 ],\n",
       "       [0.14955676],\n",
       "       [0.14669717],\n",
       "       [0.14069202],\n",
       "       [0.12839577],\n",
       "       [0.13897627],\n",
       "       [0.12439234],\n",
       "       [0.14040606],\n",
       "       [0.17843866],\n",
       "       [0.36431227],\n",
       "       [0.69688304],\n",
       "       [0.10923649],\n",
       "       [0.12267658],\n",
       "       [0.16728625],\n",
       "       [0.13983414],\n",
       "       [0.13154132],\n",
       "       [0.12982556],\n",
       "       [0.14326566],\n",
       "       [0.13440092],\n",
       "       [0.14412353],\n",
       "       [0.19616814],\n",
       "       [0.40806405],\n",
       "       [0.71661424],\n",
       "       [0.11323992],\n",
       "       [0.12982556],\n",
       "       [0.17872462],\n",
       "       [0.17615099],\n",
       "       [0.14212182],\n",
       "       [0.14097798],\n",
       "       [0.14669717],\n",
       "       [0.14240778],\n",
       "       [0.16442665],\n",
       "       [0.19330855],\n",
       "       [0.39691164],\n",
       "       [0.70803546],\n",
       "       [0.14183586],\n",
       "       [0.17615099],\n",
       "       [0.19845582],\n",
       "       [0.16585645],\n",
       "       [0.17443523],\n",
       "       [0.1584215 ],\n",
       "       [0.15641979],\n",
       "       [0.15727767],\n",
       "       [0.16642837],\n",
       "       [0.19988562],\n",
       "       [0.39147841],\n",
       "       [0.6894481 ],\n",
       "       [0.13068344],\n",
       "       [0.14498141],\n",
       "       [0.19416643],\n",
       "       [0.15584787],\n",
       "       [0.1584215 ],\n",
       "       [0.14097798],\n",
       "       [0.15527595],\n",
       "       [0.16585645],\n",
       "       [0.1704318 ],\n",
       "       [0.22104661],\n",
       "       [0.45095796],\n",
       "       [0.77637975],\n",
       "       [0.12668001],\n",
       "       [0.14726909],\n",
       "       [0.18444381],\n",
       "       [0.1795825 ],\n",
       "       [0.17214756],\n",
       "       [0.14669717],\n",
       "       [0.17472119],\n",
       "       [0.17586503],\n",
       "       [0.19445239],\n",
       "       [0.22447812],\n",
       "       [0.44867029],\n",
       "       [0.84072062],\n",
       "       [0.1584215 ],\n",
       "       [0.16700029],\n",
       "       [0.21361167],\n",
       "       [0.18530169],\n",
       "       [0.18844724],\n",
       "       [0.16585645],\n",
       "       [0.17586503],\n",
       "       [0.1781527 ],\n",
       "       [0.20217329],\n",
       "       [0.2450672 ],\n",
       "       [0.45610523],\n",
       "       [0.85902202],\n",
       "       [0.1781527 ],\n",
       "       [0.18673148],\n",
       "       [0.23076923],\n",
       "       [0.19531027],\n",
       "       [0.19302259],\n",
       "       [0.17700886],\n",
       "       [0.19159279],\n",
       "       [0.19130683],\n",
       "       [0.21303975],\n",
       "       [0.2450672 ],\n",
       "       [0.47640835],\n",
       "       [0.82070346],\n",
       "       [0.17329139],\n",
       "       [0.17300543],\n",
       "       [0.22276237],\n",
       "       [0.20074349],\n",
       "       [0.19187875],\n",
       "       [0.17214756],\n",
       "       [0.17643695],\n",
       "       [0.19073492],\n",
       "       [0.22076065],\n",
       "       [0.24849871]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9529f9a3b7e28cb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.279070Z",
     "start_time": "2025-04-09T04:07:27.264559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_sequences_torch(data_A, data_B, data_C, min_length=12):\n",
    "    output_seq = []\n",
    "    target = []\n",
    "    \n",
    "    for x in range(min_length, len(data_A) - 1):\n",
    "        inner_seq = torch.tensor(np.column_stack((\n",
    "            data_A[:x], \n",
    "            data_B[:x], \n",
    "            data_C[:x]\n",
    "        )), dtype=torch.float)\n",
    "        \n",
    "        output_seq.append(inner_seq)\n",
    "        target.append(data_C[x + 1])  \n",
    "\n",
    "    padded_seq = torch.nn.utils.rnn.pad_sequence(output_seq, batch_first=True, padding_value=0)\n",
    "\n",
    "    return padded_seq, torch.tensor(target, dtype=torch.float32)"
   ],
   "id": "c494ee32548527ee",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.310627Z",
     "start_time": "2025-04-09T04:07:27.280579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_seq, train_targets = create_sequences_torch(scaled_train_data_A, scaled_train_data_B, scaled_train_data_C)\n",
    "test_seq, test_targets = create_sequences_torch(scaled_test_data_A, scaled_test_data_B, scaled_test_data_C)"
   ],
   "id": "fcddc88136c2c135",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tongc\\AppData\\Local\\Temp\\ipykernel_21544\\998990354.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  return padded_seq, torch.tensor(target, dtype=torch.float32)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.326159Z",
     "start_time": "2025-04-09T04:07:27.312640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(train_seq.shape)\n",
    "print(train_targets.shape)"
   ],
   "id": "dac0353ab03c7c8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([297, 308, 3])\n",
      "torch.Size([297, 1])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.342190Z",
     "start_time": "2025-04-09T04:07:27.328159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def get_lengths(padded_sequences):\n",
    "        mask = (padded_sequences.abs().sum(dim=2) > 0).int()\n",
    "        lengths = mask.sum(dim=1) \n",
    "        return lengths\n",
    "\n",
    "\n",
    "class PreprocessedDataset(Dataset):\n",
    "    def __init__(self, padded_sequences, labels):\n",
    "        self.padded_sequences = padded_sequences \n",
    "        self.labels = labels  \n",
    "        self.lengths = get_lengths(padded_sequences)  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.padded_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.padded_sequences[idx], self.lengths[idx], self.labels[idx]\n",
    "\n",
    "    \n",
    "    \n",
    "def collate_fn(batch):\n",
    "    sequences, lengths, labels = zip(*batch) \n",
    "\n",
    "    sequences = torch.stack(sequences)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    lengths, sort_idx = lengths.sort(descending=True)\n",
    "    sorted_sequences = sequences[sort_idx]\n",
    "    sorted_labels = labels[sort_idx]\n",
    "\n",
    "    _, original_order = sort_idx.sort()\n",
    "\n",
    "    return sorted_sequences, lengths, sorted_labels, original_order\n",
    "\n",
    "train_set = PreprocessedDataset(train_seq, train_targets)\n",
    "test_set = PreprocessedDataset(test_seq, test_targets)\n",
    "\n",
    "train_loader = DataLoader(train_set, \n",
    "                        batch_size=64, \n",
    "                        shuffle=False,\n",
    "                        collate_fn=collate_fn) \n",
    "\n",
    "test_loader = DataLoader(test_set, \n",
    "                       batch_size=64, \n",
    "                       shuffle=False,\n",
    "                       collate_fn=collate_fn) "
   ],
   "id": "727f51327ab2b5f4",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.357716Z",
     "start_time": "2025-04-09T04:07:27.344198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in train_loader:\n",
    "    sequences, lengths, labels, _ = batch\n",
    "    print(f\"Batch shapes - Sequences: {sequences.shape}, Labels: {labels.shape}\")\n",
    "    break"
   ],
   "id": "44ebb9b14a99144c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes - Sequences: torch.Size([64, 308, 3]), Labels: torch.Size([64])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:27.373657Z",
     "start_time": "2025-04-09T04:07:27.360715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, bidirectional):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        fc_input_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, \n",
    "                          hidden_size, \n",
    "                          num_layers, \n",
    "                          batch_first=True,\n",
    "                          dropout=dropout,\n",
    "                        bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(fc_input_size, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x, lengths, original_order=None):\n",
    "\n",
    "        lengths = lengths.cpu()\n",
    "        \n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(\n",
    "            x, \n",
    "            lengths, \n",
    "            batch_first=True, \n",
    "            enforce_sorted=True\n",
    "        )\n",
    "        \n",
    "\n",
    "        num_directions = 2 if self.lstm.bidirectional else 1\n",
    "        h0 = torch.zeros(self.num_layers * num_directions, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers * num_directions, x.size(0), self.hidden_size).to(x.device)\n",
    "    \n",
    "        \n",
    "        packed_out, (hn, cn) = self.lstm(packed_input, (h0, c0))\n",
    "        \n",
    "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        \n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        last_seq_idxs = lengths - 1\n",
    "        out = out[torch.arange(out.shape[0]), last_seq_idxs]\n",
    "        \n",
    "        if original_order is not None:\n",
    "            out = out[original_order]\n",
    "        \n",
    "        \n",
    "        out = self.fc(out)\n",
    "        #out = self.out(out)\n",
    "        return out.squeeze(1)\n"
   ],
   "id": "630a863e2ff65510",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T04:07:29.128560Z",
     "start_time": "2025-04-09T04:07:27.375235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "input_size = 3 \n",
    "hidden_size = 192\n",
    "num_layers = 3\n",
    "dropout = 0.6\n",
    "learning_rate = 0.001\n",
    "num_epochs = 250\n",
    "\n",
    "model = LSTMModel(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    bidirectional= True\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, scheduler, patience=10):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_test_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for batch_idx, (sorted_sequences, lengths, sorted_labels, original_order) in enumerate(train_loader):\n",
    "            sequences = sorted_sequences.to(device)\n",
    "            labels = sorted_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences, lengths)\n",
    "            loss = criterion(outputs.view(-1), labels.view(-1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * sequences.size(0)\n",
    "            total_samples += sequences.size(0)\n",
    "        \n",
    "        epoch_train_loss = running_loss / total_samples\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        total_test_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for sequences, lengths, targets, _ in test_loader:\n",
    "                sequences = sequences.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                outputs = model(sequences, lengths)\n",
    "                loss = criterion(outputs.view(-1), targets.view(-1).float())\n",
    "                \n",
    "                test_loss += loss.item() * sequences.size(0)\n",
    "                total_test_samples += sequences.size(0)\n",
    "        \n",
    "        epoch_test_loss = test_loss / total_test_samples\n",
    "        test_losses.append(epoch_test_loss)\n",
    "\n",
    "        if epoch_test_loss < best_test_loss:\n",
    "            best_test_loss = epoch_test_loss\n",
    "            epochs_without_improvement = 0  \n",
    "        if (epoch+1)%50 == 0:\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            print(f\"Epoch: {epoch+1}/{num_epochs} | \"\n",
    "                  f\"Train Loss: {epoch_train_loss:.4f} | \"\n",
    "                  f\"Test Loss: {epoch_test_loss:.4f} |\"\n",
    "                  f\"LR: {current_lr}\")\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}. No improvement for {patience} epochs.\")\n",
    "            break\n",
    "        scheduler.step()\n",
    "    return train_losses, test_losses\n",
    "class Case(Enum):\n",
    "    test = \"Test\"\n",
    "    train = \"Train\"\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, case):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, seq_lengths, targets, _ in test_loader: \n",
    "            sequences = sequences.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(sequences, seq_lengths)\n",
    "            loss = criterion(outputs.view(-1), targets.view(-1).float())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = outputs.cpu().numpy()\n",
    "            targets_np = targets.cpu().numpy()\n",
    "   \n",
    "            all_preds.extend(preds.flatten())\n",
    "            all_targets.extend(targets_np.flatten())\n",
    "\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    mse = mean_squared_error(all_targets, all_preds)\n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "    \n",
    "    \n",
    "    print(f'{case.value} Loss: {avg_loss:.4f} | MSE: {mse:.4f} | MAE: {mae:.4f} | RÂ²: {r2:.4f}')\n",
    "    return all_preds, all_targets\n",
    "\n",
    "def plot_loss_curves(train_losses, test_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(test_losses, label='Test Loss')\n",
    "    plt.title('Training and Test Loss Curves')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_result(predictions, targets, title='Train vs Actual'):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Create an index array for plotting\n",
    "    idx = np.arange(len(targets))\n",
    "    \n",
    "    # Plot both arrays\n",
    "    plt.plot(idx, targets, label='Actual Values', alpha=0.7)\n",
    "    plt.plot(idx, predictions, label='Predicted Values', alpha=0.5)\n",
    "    \n",
    "    # Add plot formatting\n",
    "    plt.title(f'{title}')\n",
    "    plt.xlabel('Sequence Index')\n",
    "    plt.ylabel('Target Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "e5deb430a6b70a7b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-09T04:07:29.129576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "train_losses,test_losses = train_model(model, train_loader,test_loader, criterion, optimizer, num_epochs,scheduler)\n",
    "\n",
    "plot_loss_curves(train_losses,test_losses)\n",
    "\n",
    "# Evaluate the model\n",
    "train_preds, train_targets = evaluate_model(model, train_loader, criterion, Case.train)\n",
    "test_pred, actual_Label = evaluate_model(model, test_loader, criterion, Case.test)\n",
    "\n",
    "# Plot results\n",
    "plot_result(train_preds,train_targets, title=\"Train vs label\")\n",
    "plot_result(test_pred, actual_Label, title=\"Test vs label\")"
   ],
   "id": "c607ac54788c15ef",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
